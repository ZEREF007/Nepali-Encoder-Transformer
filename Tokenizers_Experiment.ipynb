{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lO8sCeGFp69"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1B_bZvewIOo",
        "outputId": "b62c6cd9-8181-4012-e1d3-bee3d175558c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Apr 10 14:17:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RPvFtf3hQH8",
        "outputId": "6d4140d1-631a-46a2-9e3e-1cb5eba95212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Command line option 'U' [from -Uqq] is not understood in combination with the other options.\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq datasets transformers[sentencepiece]\n",
        "!pip install -Uqq accelerate\n",
        "!apt install -Uqq git-lfs\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o96WlSBd9rz",
        "outputId": "7c59ae62-0862-40dd-885a-1993f5ccdd83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=NLMUT_CLF\n",
            "env: WANDB_LOG_MODEL=true\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ],
      "source": [
        "%reload_ext autoreload\n",
        "# %autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "%env WANDB_PROJECT=NLMUT_CLF\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env TOKENIZERS_PARALLELISM = true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-mvtRq1d9r8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJwxmAq7HmU3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPYI7ccuF6Zj"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "d3b234dc14e240378da0ef414099cd6e",
            "477422a0d59a41ef9730e31aa53e79d1",
            "d3c20717e97c448ca3c28fb6641217c6",
            "fba2f8821114446fa9b7afe7d4764af2",
            "23c609c4fdf649768a2f88981edcdff1",
            "a224f24787884bfa947e8f93291c3437",
            "c844d078f9bd42caae0b4438719eeff9",
            "c871686b1fb44498a626ffb8245e5e40",
            "f5a651b9f3954090856304a36fe95a74",
            "8f5deda705574d9f94f603e597ab9dee",
            "7301bd2dac6d4fa7b50335f006729b15",
            "bfb40e7f2b234b5798eae0c06239cc35",
            "28c88008697e448b92130ba83a19fa37",
            "38f10c106e1948b8ba7ca108b576abe1",
            "3a5f54064b4e4e4e9b831445cdeba971",
            "fcb137e4046b4a338186bbf659fb4c2a",
            "9aa96e310e2442fb930513ff012fdabd"
          ]
        },
        "id": "rSrc1VPQLiN5",
        "outputId": "ce5b655d-d823-4b94-98fa-f58a25a0c522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llkagfXYcUFy",
        "outputId": "117e6623-ec52-4272-a739-59f865c9798a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcohlem\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -Uqq wandb\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-1SFcQGd9ru",
        "tags": []
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dek0SRUtZS2",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## 16NepaliNews\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWmPyjo2TGtN"
      },
      "outputs": [],
      "source": [
        "!wget --header \"Host: raw.githubusercontent.com\" --user-agent \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\" --header \"Accept-Language: en-US,en;q=0.5\" --referer \"https://github.com/sndsabin/Nepali-News-Classifier/blob/master/16NepaliNews.rar\" --header \"Upgrade-Insecure-Requests: 1\" --header \"Sec-Fetch-Dest: document\" --header \"Sec-Fetch-Mode: navigate\" --header \"Sec-Fetch-Site: cross-site\" --header \"Sec-Fetch-User: ?1\" \"https://raw.githubusercontent.com/sndsabin/Nepali-News-Classifier/master/16NepaliNews.rar\" --output-document \"16NepaliNews.rar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPaG7ZBoeuOA"
      },
      "outputs": [],
      "source": [
        "# !rm -rf 16NepaliNews/\n",
        "!unrar x 16NepaliNews.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7JUxg6hqydM"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# !mkdir ./16NepaliNews/16719\n",
        "path = Path('./16NepaliNews/16719')\n",
        "path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_ypFRwUtU3I",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## Nepali News Dataset Large\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQ0uYkXgk66"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhMnOGHGgk9A"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d ashokpant/nepali-news-dataset-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWqmKDqDgk_H"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfqTI8s2glBK"
      },
      "outputs": [],
      "source": [
        "!unzip nepali-news-dataset-large.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3zykg4oglDh"
      },
      "outputs": [],
      "source": [
        "ls nepali_news_dataset_20_categories_large/nepali_news_dataset_20_categories_large/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHiC1yo7teNe"
      },
      "outputs": [],
      "source": [
        "path = Path('./nepali_news_dataset_20_categories_large/nepali_news_dataset_20_categories_large/')\n",
        "path.ls()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Tsgz94WEhr",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "# Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMxfEmv3ZyDD"
      },
      "outputs": [],
      "source": [
        "# from sklearn import datasets\n",
        "from sklearn.datasets import load_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttNmaSZP0_RP"
      },
      "outputs": [],
      "source": [
        "dataset = load_files(path/'train/', encoding=\"utf-8\", decode_error=\"ignore\", shuffle=False)\n",
        "dataset_valid = load_files(path/'test/', encoding=\"utf-8\", decode_error=\"ignore\", shuffle=False)\n",
        "dir(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWLF2Mmu9XU3"
      },
      "outputs": [],
      "source": [
        "label_map = dict()\n",
        "for i,name in enumerate(dataset.target_names):\n",
        "  label_map[i] = name\n",
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxQ3ETOl0_mZ"
      },
      "outputs": [],
      "source": [
        "# Train set\n",
        "df = pd.DataFrame(data=dataset.data, columns=[\"text\"])\n",
        "df['target'] = pd.Series(dataset.target)\n",
        "# df['target'] = df['target'].map(label_map)  # Uncomment to use Strings as labels\n",
        "# df['is_valid'] = False\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9z9_fpXRHUW"
      },
      "outputs": [],
      "source": [
        "# Test set\n",
        "df_test = pd.DataFrame(data=dataset_valid.data, columns=[\"text\"])\n",
        "df_test['target'] = pd.Series(dataset_valid.target)\n",
        "# df_test['target'] = df_test['target'].map(label_map)  # Uncomment to use Strings as labels\n",
        "# df_test['is_valid'] = True\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkn0wOJGRzdd"
      },
      "outputs": [],
      "source": [
        "# df_full = pd.concat([df, df_test])\n",
        "# df_full.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0V_jhO9S-s2"
      },
      "source": [
        "## EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Fcwd7PZewY"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwYeMLCaZqWv"
      },
      "outputs": [],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZW45iHYwjsK"
      },
      "outputs": [],
      "source": [
        "df.target.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMuMiJ_r_hqt"
      },
      "outputs": [],
      "source": [
        "length = df['text'].str.split().str.len().mean()\n",
        "print(f\"Average number of words in 'text' column: {length}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7wob0ikeJ5M"
      },
      "source": [
        "length = df_test['text'].str.split().str.len().mean()\n",
        "print(f\"Average number of words in 'text' column: {length}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSV0hILNyytY"
      },
      "source": [
        "Data Cleaning goes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbWMdDBnbPfQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "  # text = re.sub('[^a-z\\s]', ' ', text.lower())\n",
        "  # text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
        "  text = re.sub('@\\w+', ' ', text)\n",
        "  text = ' '.join(text.split())\n",
        "  text.replace('\\n\\n','')\n",
        "  text.replace('\\n',' ')\n",
        "  text.replace('\\t',' ')\n",
        "  text.replace('\\r','')\n",
        "  return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "df_test['text'] = df_test['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I44JRz87v6XM"
      },
      "outputs": [],
      "source": [
        "length = df['text'].str.split().str.len().mean()\n",
        "print(f\"Average number of words in 'text' column: {length}\")\n",
        "\n",
        "length = df['text'].str.split().str.len().max()\n",
        "print(f\"Maximum number of words in 'text' column: {length}\")\n",
        "\n",
        "length = df['text'].str.split().str.len().min()\n",
        "print(f\"Minimum number of words in 'text' column: {length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUNZoQxskFOR"
      },
      "outputs": [],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc_21_U4W1G1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df['target'].value_counts().plot(kind='bar')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy11Q17v5USA"
      },
      "outputs": [],
      "source": [
        "# Number of labels before data cleaning\n",
        "num_labels = df.target.nunique()\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBSPVeTc9sBi"
      },
      "outputs": [],
      "source": [
        "# df['category'].value_counts()[117]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FHHftH7q6qr"
      },
      "outputs": [],
      "source": [
        "# Cheap undersampling\n",
        "\n",
        "# categories = df['category'].value_counts().index\n",
        "# for i in range(10):\n",
        "#   category = categories[i]\n",
        "#   num_to_remove = 12000-i*1200\n",
        "#   to_remove = np.random.choice(df[df['category']==category].index, size=num_to_remove, replace=False)\n",
        "#   df.drop(to_remove, inplace=True)\n",
        "\n",
        "# categories = df['category'].value_counts().index\n",
        "# value_counts = df['category'].value_counts()\n",
        "# for i in range(117):\n",
        "#   category = categories[i]\n",
        "#   num_to_remove = value_counts[i]- 500   # keep only 1200 data for each class having about 1200 data\n",
        "#   to_remove = np.random.choice(df[df['category']==category].index, size=num_to_remove, replace=False)\n",
        "#   df.drop(to_remove, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jehi5omLjV8o"
      },
      "outputs": [],
      "source": [
        "# df['target'].value_counts().plot(kind='bar')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhzHYNjS3DZs"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset=['text','target'], how='any', inplace=True)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmMizn02y89m"
      },
      "outputs": [],
      "source": [
        "_ = df[df.text.str.split().str.len() <= 12]\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye4rieTHxieF"
      },
      "outputs": [],
      "source": [
        "# Delete sentences with less than 4 words\n",
        "df = df[df.text.str.split().str.len() >= 4]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKYKKJCB5e2q"
      },
      "outputs": [],
      "source": [
        "# Make sure no labels are deleted\n",
        "assert(num_labels == df.target.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc7Qo-wtOas9"
      },
      "outputs": [],
      "source": [
        "df.to_csv(path_or_buf='16NepaliNews_train.csv', index=False)\n",
        "df_test.to_csv(path_or_buf='16NepaliNews_test.csv', index=False)\n",
        "\n",
        "!cp 16NepaliNews_train.csv drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_train.csv\n",
        "!cp 16NepaliNews_test.csv drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_test.csv\n",
        "\n",
        "# !cp drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_train.csv 16NepaliNews_train.csv \n",
        "# !cp drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_test.csv 16NepaliNews_test.csv \n",
        "\n",
        "# df = pd.read_csv('16NepaliNews_train.csv')\n",
        "# df_test = pd.read_csv('16NepaliNews_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSKk5w5PGCuf"
      },
      "source": [
        "## Load dataset for New Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yewT1ANnGGGM"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_train.csv 16NepaliNews_train.csv \n",
        "!cp drive/MyDrive/Colab\\ Notebooks/NLMUT/16NepaliNews_test.csv 16NepaliNews_test.csv \n",
        "\n",
        "df = pd.read_csv('16NepaliNews_train.csv')\n",
        "df_test = pd.read_csv('16NepaliNews_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkrR5N9M1RzU",
        "tags": []
      },
      "source": [
        "# Transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgQ2I0PNIQOS",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## Transformer Dataset (Define Data Loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joF99SSdGRjC"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('csv', data_files={'train': '16NepaliNews_train.csv', 'test': '16NepaliNews_test.csv' })\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCoZ_1m0G-4c"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.rename_column(\"target\", \"labels\") # This is needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Dc573b9yZY"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]\n",
        "# Note the '\\ufeff' is removed by tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpCM5VfJ_vGY"
      },
      "source": [
        "### Export Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKkgowja_yHG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login \n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHv7aZJZ_yJK"
      },
      "outputs": [],
      "source": [
        "dataset.push_to_hub(\"Sakonii/16NepaliNews\", private=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHjcpLx8Bll_"
      },
      "source": [
        "## Load Dataset from the HUB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "bbcf01e8d9264812a740d06dcbbb5fb3",
            "224875caf7364181a32f71096ad6b1f2",
            "819c329b3fbd48c89fde436ddf131ca4",
            "420e255eeb904e36a423e87e2b3d91df",
            "cf8f249f35c04374986e09aa7621c7d8",
            "86c667e6eb38437a9bd4178e20bbe1be",
            "3d4c85919ad948f889be6ca4288d1115",
            "10fbb924da50491793a9d8c7ec8e37f7",
            "d4f42d94d70e4d2d91ffa788784754f2",
            "8548e03776344dde852ef9ed23efb4df",
            "69938506e9c743f08efbf9e0c293c28f",
            "27a4bdd2ffee4fa1b728140d3f63d026",
            "6023d1806f9f4c15b905f9b8e464324e",
            "78213c9028774f409ab0c8d615077870",
            "63cdee9b24fc43159493a3ec21aeb0d7",
            "74e3820b56b74cd79683a957a934d9a8",
            "25269636d5384dbc8727dcee39e719b0"
          ]
        },
        "id": "u8QH_Ps9BoSC",
        "outputId": "c779a486-a1be-4008-c794-bf7554fe34d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "2200c2cd71e64aa5ba1f1c4d7b9da527",
            "10c910efbe01465aae96d39aac5e5a5e",
            "dcb89119c66a44ca8451e4017a5646ea",
            "3a0b9dcd7d7f41a59a7ff385a8fe8c88",
            "20c01bf44c7145b1a91852d996d6afc7",
            "c42b9bc46d9b400b8412eee53bcc47ef",
            "f569aaa0528c4ef381743ef075c5d1f3",
            "78f608d33e6c47fbb3e1038c7a013c7a",
            "547bc82d71d3418785f17bc4c51c1afb",
            "2a9a727cf2d74a09b6a3b4a9a6d3ea24",
            "7118547fc5844f7ca2e9143b4cbed80b"
          ]
        },
        "id": "23O-NO83BoUa",
        "outputId": "1a1cf883-d995-4f0b-95c8-fe407bd60364"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration Sakonii--16NepaliNews-b9065bf14077793a\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/Sakonii--16NepaliNews-b9065bf14077793a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2200c2cd71e64aa5ba1f1c4d7b9da527",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('Sakonii/16NepaliNews', streaming=False, use_auth_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31rDrL7dA3_H"
      },
      "source": [
        "## Dataset Tokenization (Changes for each model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMtmHnkBOXi5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6619d7fc4e694e07b2358e4c30ab5a7c",
            "3bba2059fcde4ecfb621ab94716ecf84",
            "aae5c112fd1a4fabbf3ca00ff246b454",
            "100def69a7d2472497d5fb0ada7c5dff",
            "f61ec379fa4f4bcb986ad2b3986d3469",
            "efb3a8f6f1aa4a92a637bb7f057ae049",
            "2f9d8b8b1e77415ebdd119f97830a8ca",
            "4e5519315df045eb8ae5c9459754629d",
            "da18174543b44352840cdfede7e71985",
            "01aeb73ae6e1475180f88cd4d0b68cab",
            "5b04baf66f614a93afb9bc55ac0e5987"
          ]
        },
        "id": "kB1EPfIZOq28",
        "outputId": "7689af2b-1efd-4402-b126-020e5112de09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/Rajan/NepaliBERT/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1246361fd733d7f81601e855a3204506449f8b226745d66f58d4f84eaf201c41.36e4050a7f8f6f24536203f25cff98ef0c38bcd695bb9d1efbf39e3b09b9f273\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"Rajan/NepaliBERT\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n",
            "https://huggingface.co/Rajan/NepaliBERT/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3zd71w_3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6619d7fc4e694e07b2358e4c30ab5a7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/964k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Rajan/NepaliBERT/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/a3ba5495a5249c5164e69fe430d3d126ad5d6427a55ee70274a812964bbc34f9.2f6fd7c2709e1ba46b4621a2d5f609a09ebe36450249b60d6abad04c53e61f7c\n",
            "creating metadata file for /root/.cache/huggingface/transformers/a3ba5495a5249c5164e69fe430d3d126ad5d6427a55ee70274a812964bbc34f9.2f6fd7c2709e1ba46b4621a2d5f609a09ebe36450249b60d6abad04c53e61f7c\n",
            "loading file https://huggingface.co/Rajan/NepaliBERT/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/a3ba5495a5249c5164e69fe430d3d126ad5d6427a55ee70274a812964bbc34f9.2f6fd7c2709e1ba46b4621a2d5f609a09ebe36450249b60d6abad04c53e61f7c\n",
            "loading file https://huggingface.co/Rajan/NepaliBERT/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/Rajan/NepaliBERT/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Rajan/NepaliBERT/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/Rajan/NepaliBERT/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/Rajan/NepaliBERT/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1246361fd733d7f81601e855a3204506449f8b226745d66f58d4f84eaf201c41.36e4050a7f8f6f24536203f25cff98ef0c38bcd695bb9d1efbf39e3b09b9f273\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"Rajan/NepaliBERT\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/Rajan/NepaliBERT/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1246361fd733d7f81601e855a3204506449f8b226745d66f58d4f84eaf201c41.36e4050a7f8f6f24536203f25cff98ef0c38bcd695bb9d1efbf39e3b09b9f273\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"Rajan/NepaliBERT\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Rajan/NepaliBERT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HWPQe54PKd5"
      },
      "outputs": [],
      "source": [
        "tokens1 = tokenizer.tokenize(\"यता काठमाडौंको चन्द्रागिरिमा पनि हिउँ खेल्न हिँडेका पाँच जना बालबालिका बेपत्ता भएका थिए।\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEOhGBPAPOdB",
        "outputId": "f47fc702-0aee-4afa-86bb-baf28c6cddf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['यता',\n",
              " 'काठमाडौको',\n",
              " 'चन',\n",
              " '##दर',\n",
              " '##ागि',\n",
              " '##रिम',\n",
              " '##ा',\n",
              " 'पनि',\n",
              " 'हिउ',\n",
              " 'खल',\n",
              " '##न',\n",
              " 'हिड',\n",
              " '##का',\n",
              " 'पाच',\n",
              " 'जना',\n",
              " 'बालबालिका',\n",
              " 'ब',\n",
              " '##पत',\n",
              " '##ता',\n",
              " 'भएका',\n",
              " 'थिए',\n",
              " '।']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhNVm21y2XEo",
        "outputId": "129faf0f-a43e-473b-d971-06bebd0fa7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndken-AIPgX7",
        "outputId": "535a8403-c9aa-4cc7-e850-9b2290ed5131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'NepaliBERT' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/Rajan/NepaliBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9HC9GZqPlk4"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "vocab_file_dir = './NepaliBERT/' \n",
        "tokenizer_rajan = BertTokenizer.from_pretrained(vocab_file_dir,\n",
        "                                     strip_accents=False,\n",
        "                                      clean_text=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmYV05JNPuBt",
        "outputId": "395869d8-a141-4ecf-f54c-b7bbeb877034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['यता',\n",
              " 'काठमाडौंको',\n",
              " 'चन्द्रागिरि',\n",
              " '##मा',\n",
              " 'पनि',\n",
              " 'हिउँ',\n",
              " 'खेल्न',\n",
              " 'हिँडेका',\n",
              " 'पाँच',\n",
              " 'जना',\n",
              " 'बालबालिका',\n",
              " 'बेपत्ता',\n",
              " 'भएका',\n",
              " 'थिए',\n",
              " '।']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer_rajan.tokenize(\"यता काठमाडौंको चन्द्रागिरिमा पनि हिउँ खेल्न हिँडेका पाँच जना बालबालिका बेपत्ता भएका थिए।\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGLZ7N-WSHhf"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuMxUUVP8GRZ",
        "outputId": "cc5dff43-bcfb-4703-bafb-ca77143a7958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 12918\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 1446\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2667d5c2e09e4d3b85eb253e7029105e",
            "ed387bf621994c7c81c46778b83c942d",
            "adefb92dbb33405ba4c97520fac3aa71",
            "2b25268aa2b1466bb6a294ea921c786f",
            "b0c19f4eec3b4cf597342bd0a4658d05",
            "84848296a05e41238d9e7fa76ca357f1",
            "37edd3df6aa549c7a419364f20063669",
            "d283bd3eb55e43d38c873f4892105082",
            "9c39e87bc68d4d12900ca258b582263a",
            "2f445dd46d1a4014a24985901ff22d77",
            "72cae5449de04a10930b0acc92e83ab8",
            "d8a5899196694978b9945444cae8df10",
            "755b497bb1e7480d8ac80b68702f4c85",
            "d36e39a733304b48ba5e44cf9100d2f6",
            "b2bd0d4f1d2543c3a8b4d2c60d57f542",
            "60f61fd8c3f840f8ae4ac42c3db83fa1",
            "522ec6cf07c34acb9a51e61cb11260f9",
            "e2830c743f884d118de538c76642a351",
            "e7bf5db35d3c4afa9e56571f3d75118b",
            "0d4ee81856c14efbb6ba9ce9f2091154",
            "6f844501897f4c58a5826bcdf2bfcfaf",
            "30258314778e4e049d96e37892cda4a3"
          ]
        },
        "id": "of6vh2WkGRuy",
        "outputId": "fcdeaebf-44f9-435f-ba43-79893c07077a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2667d5c2e09e4d3b85eb253e7029105e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8a5899196694978b9945444cae8df10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Sakonii/de-berta-base-base-nepali\", use_auth_token=True, cache_dir=\"/mnt/storage0/common/Sakonii\") # xlm-roberta-base Sakonii/distilbert-base-nepali \n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"Shushant/nepaliBERT\", model_max_length=512, cache_dir=\"/mnt/storage0/common/Sakonii\")   # Shushant/nepaliBERT Rajan/NepaliBERT\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer_rajan(example[\"text\"], truncation=True, padding=True, max_length = 510 )\n",
        "\n",
        "dataset = dataset.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_rajan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcYfpXUCHqWB",
        "outputId": "bba1e027-fa3c-4871-c8a5-e190ce0d08be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 12918\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1446\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POHfdXrrLiOH"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "55b7433473e14184bf382e7e589dcf16",
            "c942f7bf535946d688bf26c50a107962",
            "c4087d3aaf8643dc8a76f4a6ed8b3b25",
            "d0ce1afc1df141be9a1e94c7f840b33f",
            "34c90f8222eb4063b4e460fdfdbd28da",
            "e95babf12826482c9ff5065ab844b0f1",
            "19f98f725b8e49e6bbea948ae4265d6c",
            "f61fc3c0c48e4a939b97dfe5c7076af8",
            "12b4a2b16e9f4714aceefc0435194287",
            "1711b157d65a461e80c50565f8ecd18d",
            "c0d59ae181a04613b0402f7bdac68700",
            "c3bd3ee8380c42b78bae8488e42e5df4",
            "cba992151adb4291a7d7502b9f74f58a",
            "0694e0ba0418483abd29b15c33d96221",
            "f4993acbc56b42f5a19e7dd402c08366",
            "b136a9d38f08450cba9a046dbe17f2cd",
            "1c5103e1f150406c9c10ce47577120c0",
            "2eff3a77dde841bf83cf6f14ecb87948",
            "5a98a21e322342c09855d5a3a035a9b6",
            "776da3688d5b4ffdadb570ff89241efc",
            "e766665540524efb8f46672981937f5a",
            "a87203c1372a4c94a51773c67cd74749"
          ]
        },
        "id": "AmFCfMIRDh3K",
        "outputId": "2dc65505-b6c5-4d3f-bd6c-5e86617eb2b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b7433473e14184bf382e7e589dcf16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12918 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3bd3ee8380c42b78bae8488e42e5df4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1446 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure there are only 'input_ids', 'labels' and 'attention_mask' columns\n",
        "remove_columns = ['text'] # 'token_type_ids'\n",
        "dataset = dataset.map(remove_columns=remove_columns)  # (because the model expects the argument to be named labels)\n",
        "\n",
        "dataset.set_format(\"torch\")\n",
        "dataset[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9hy9NhaDaR_",
        "outputId": "7d0eafca-8acb-4313-fc4d-7603e927cd02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']['labels'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nk8zGZ62SBF"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWQityL0VbHV",
        "outputId": "a99d29d7-537d-4db1-dc20-b2d276f329ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwZO1NfWVu5y",
        "outputId": "f6126583-c94d-4f5c-9b71-ff1f0c3b7c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "git: 'lfs' is not a git command. See 'git --help'.\n",
            "\n",
            "The most similar command is\n",
            "\tlog\n"
          ]
        }
      ],
      "source": [
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR5xUGRhV07d",
        "outputId": "c28e969b-58b2-4fcf-a3a8-5fd378b7c46c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Not in a git repository.\n"
          ]
        }
      ],
      "source": [
        "!git lfs pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8dFqA_O1ROj",
        "outputId": "2fa24e75-adb8-444d-9104-06f0764a59b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Rajan/NepaliBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Rajan/NepaliBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Rajan/NepaliBERT\", use_auth_token=True, num_labels=16)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6UQXr7bZ56V",
        "outputId": "b748e6d7-1bba-405f-a621-7d98d34fceb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 17.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 22.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 736 kB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "woWzezLxaBP7",
        "outputId": "afb7f046-ffeb-4437-8aab-4e6f5f6ef849"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HokLjqpuIbCc",
        "outputId": "b0783d7c-7107-4060-8e99-ba2a1703be4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/New\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_steps=5,\n",
        "    learning_rate=3e-5,\n",
        "    save_steps=50000, #\n",
        "    weight_decay=0.01,\n",
        "    fp16=True, \n",
        "    num_train_epochs=5,\n",
        "    lr_scheduler_type='linear',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_ratio=0.0, \n",
        "    warmup_steps=0,\n",
        "    seed=86,\n",
        "    push_to_hub=True,\n",
        "    report_to=\"wandb\",    \n",
        "    run_name=\"ClassificationOnrajanNepalibert\",\n",
        "    hub_model_id=\"CohleM/ClassificationOnNepaliBert\", \n",
        "    save_strategy=\"epoch\" \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y7cgWD44Ubc"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     metric1 = load_metric(\"accuracy\")\n",
        "#     metric2 = load_metric(\"f1\")\n",
        "    \n",
        "#     logits, labels = eval_pred\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "#     accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "#     f1 = metric2.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "#     return {\"accuracy\": accuracy, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5LdzStd5mOm"
      },
      "outputs": [],
      "source": [
        "# !sudo apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8s-Eo_YIbIC",
        "outputId": "6676d18f-43f2-40c3-df2f-38dbe5624233"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/New is already a clone of https://huggingface.co/CohleM/ClassificationOnNepaliBert. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer_rajan,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMq9UD3DLiOJ"
      },
      "source": [
        "### deberta-base-nepali [ours]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "Lb27zCEoLiOJ",
        "outputId": "93d2af6d-32b9-444e-9ee3-1c7b5ad71f22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1615\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='561' max='1615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 561/1615 12:49 < 24:10, 0.73 it/s, Epoch 0.35/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# lr=3e-5, bs=8, vram_load_titanv=94.73%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "467561152a424a7982505cff328ef7bd"
          ]
        },
        "id": "Pj4lb7ScLiOJ",
        "outputId": "3782274a-7ed2-41cc-95ae-84423b9e9b1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8075\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220409_150351-816s9zzz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/talentless-us/NLMUT_CLF/runs/816s9zzz\" target=\"_blank\">deberta-base-ours-clf-bs_32-lr_1e-5</a></strong> to <a href=\"https://wandb.ai/talentless-us/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8075' max='8075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8075/8075 1:05:11, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.346600</td>\n",
              "      <td>0.466475</td>\n",
              "      <td>0.860304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.814200</td>\n",
              "      <td>0.446826</td>\n",
              "      <td>0.877593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.358400</td>\n",
              "      <td>0.456466</td>\n",
              "      <td>0.884509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.263800</td>\n",
              "      <td>0.558176</td>\n",
              "      <td>0.880360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.644176</td>\n",
              "      <td>0.870678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-1615\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-1615/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-1615/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-1615/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-1615/special_tokens_map.json\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-3230\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-3230/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-3230/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-3230/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-3230/special_tokens_map.json\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-4845\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-4845/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-4845/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-4845/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-4845/special_tokens_map.json\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-6460\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-6460/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-6460/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-6460/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-6460/special_tokens_map.json\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-8075\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-8075/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-8075/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-8075/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/checkpoint-8075/special_tokens_map.json\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/ is already a clone of https://huggingface.co/Sakonii/deberta-base-nepali-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp3o5jescp\n",
            "Configuration saved in /tmp/tmp3o5jescp/config.json\n",
            "Model weights saved in /tmp/tmp3o5jescp/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp3o5jescp/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp3o5jescp/special_tokens_map.json\n",
            "Saving model checkpoint to /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/\n",
            "Configuration saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/config.json\n",
            "Model weights saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/pytorch_model.bin\n",
            "tokenizer config file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in /mnt/storage0/common/Sakonii/clf-16NepaliNews-train_/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "467561152a424a7982505cff328ef7bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/531M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at e65ed0dab556bf7e68ede7553c6bfe1294b22105 but expected 9e96016c0c4afca680513d3a6dd9d6b3cc80b4ff        \n",
            "To https://huggingface.co/Sakonii/deberta-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/deberta-base-nepali-clf'\n",
            "\n",
            "Error pushing update to the model card. Please read logs and retry.\n",
            "$remote: error: cannot lock ref 'refs/heads/main': is at e65ed0dab556bf7e68ede7553c6bfe1294b22105 but expected 9e96016c0c4afca680513d3a6dd9d6b3cc80b4ff        \n",
            "To https://huggingface.co/Sakonii/deberta-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/deberta-base-nepali-clf'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8075, training_loss=0.32745903177065744, metrics={'train_runtime': 3047.9356, 'train_samples_per_second': 21.191, 'train_steps_per_second': 2.649, 'total_flos': 1.980527512928256e+16, 'train_loss': 0.32745903177065744, 'epoch': 5.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lr=2e-5, bs=8, vram_load_titanv=94.73%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhqzCl78LiOK"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMBcj8V6LiOK",
        "tags": []
      },
      "source": [
        "### Sushant/nepaliBert\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d5fbbb268a0746f3b8ba931d10cc0c99"
          ]
        },
        "id": "CPoPbMFDLiOK",
        "outputId": "456f8864-3107-4a80-f992-8ddb72ad5555"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 12\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5385\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msakonii\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220328_022514-2i3249eo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/2i3249eo\" target=\"_blank\">nepaliBERT-clf-bs_12-lr_2e-5</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5385' max='5385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5385/5385 33:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.396300</td>\n",
              "      <td>0.575537</td>\n",
              "      <td>0.834716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.346500</td>\n",
              "      <td>0.526764</td>\n",
              "      <td>0.850622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.252400</td>\n",
              "      <td>0.562476</td>\n",
              "      <td>0.859613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.385200</td>\n",
              "      <td>0.700212</td>\n",
              "      <td>0.838866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.243800</td>\n",
              "      <td>0.752423</td>\n",
              "      <td>0.843707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1077\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1077/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1077/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1077/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1077/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2154\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2154/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2154/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2154/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2154/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-3231\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-3231/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-3231/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-3231/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-3231/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-4308\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-4308/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-4308/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-4308/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-4308/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-5385\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-5385/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-5385/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-5385/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-5385/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp3m1r0977\n",
            "Configuration saved in /tmp/tmp3m1r0977/config.json\n",
            "Model weights saved in /tmp/tmp3m1r0977/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp3m1r0977/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp3m1r0977/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5fbbb268a0746f3b8ba931d10cc0c99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at abe4835479ca65aa7ca092ab5cd8dbd3e3ba4845 but expected c63d6a278212d2f0f5fee48d0751d8c2d9149ba2        \n",
            "To https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16'\n",
            "\n",
            "Error pushing update to the model card. Please read logs and retry.\n",
            "$remote: error: cannot lock ref 'refs/heads/main': is at abe4835479ca65aa7ca092ab5cd8dbd3e3ba4845 but expected c63d6a278212d2f0f5fee48d0751d8c2d9149ba2        \n",
            "To https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5385, training_loss=0.3686351099275502, metrics={'train_runtime': 1432.7696, 'train_samples_per_second': 45.081, 'train_steps_per_second': 3.758, 'total_flos': 1.699647926059008e+16, 'train_loss': 0.3686351099275502, 'epoch': 5.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lr=2e-5, bs=12, vram_load_titanv=92.81%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "29b3d7a6366c48cba68edfa46e8aba7a"
          ]
        },
        "id": "KRN51QHuLiOK",
        "outputId": "b40d3238-a710-43d4-ab64-fd11a79d4a1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8075\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220327_154339-mdpqtskw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/mdpqtskw\" target=\"_blank\">nepaliBERT-clf-bs_8-lr_3e-5</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8075' max='8075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8075/8075 36:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.386600</td>\n",
              "      <td>0.625739</td>\n",
              "      <td>0.816044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.757200</td>\n",
              "      <td>0.747594</td>\n",
              "      <td>0.816044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>0.794065</td>\n",
              "      <td>0.846473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>0.895345</td>\n",
              "      <td>0.847856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>1.003374</td>\n",
              "      <td>0.845781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1615\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1615/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1615/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1615/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1615/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-3230\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-3230/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-3230/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-3230/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-3230/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-4845\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-4845/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-4845/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-4845/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-4845/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-6460\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-6460/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-6460/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-6460/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-6460/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-8075\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-8075/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-8075/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-8075/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-8075/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmpig8gb2m6\n",
            "Configuration saved in /tmp/tmpig8gb2m6/config.json\n",
            "Model weights saved in /tmp/tmpig8gb2m6/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpig8gb2m6/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpig8gb2m6/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29b3d7a6366c48cba68edfa46e8aba7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at 0a7067f7d9e5af65eec3fc5524909a593179a18e but expected 09e41e8f50a137fe301ef738ea5c9f968784f148        \n",
            "To https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16'\n",
            "\n",
            "Error pushing update to the model card. Please read logs and retry.\n",
            "$remote: error: cannot lock ref 'refs/heads/main': is at 0a7067f7d9e5af65eec3fc5524909a593179a18e but expected 09e41e8f50a137fe301ef738ea5c9f968784f148        \n",
            "To https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBERT-Sushant-clf-NepaliNews16'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8075, training_loss=0.34104878414526074, metrics={'train_runtime': 1582.6562, 'train_samples_per_second': 40.811, 'train_steps_per_second': 5.102, 'total_flos': 1.699647926059008e+16, 'train_loss': 0.34104878414526074, 'epoch': 5.0})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Z# lr=3e-5, bs=8, vram_load_titanv=71.08%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-x02yCELiOK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ07azGqLiOK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xH7oHnyLiOK",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Rajan/NepaliBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a79a7e39f46e4591a73b03fcaae5f79f"
          ]
        },
        "id": "Z1-YedHrLiOL",
        "outputId": "debd4fcd-3b68-4710-aa29-b7e9c4d08865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 26\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 26\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2485\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220327_150948-3rqrn7r3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/3rqrn7r3\" target=\"_blank\">NepaliBERT-clf-bs_26-lr_3e-5-linear_lr_scheduler</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2485' max='2485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2485/2485 20:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.638600</td>\n",
              "      <td>0.842308</td>\n",
              "      <td>0.731674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.467000</td>\n",
              "      <td>0.713890</td>\n",
              "      <td>0.790456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.321000</td>\n",
              "      <td>0.740518</td>\n",
              "      <td>0.799447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.301700</td>\n",
              "      <td>0.714793</td>\n",
              "      <td>0.809820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.172100</td>\n",
              "      <td>0.756029</td>\n",
              "      <td>0.807746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-497\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-497/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-497/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-497/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-497/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-994\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-994/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-994/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-994/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-994/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1491\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1491/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1491/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1491/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1491/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1988\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1988/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1988/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1988/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1988/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2485\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2485/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2485/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2485/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2485/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/nepaliBert-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp307g0vvd\n",
            "Configuration saved in /tmp/tmp307g0vvd/config.json\n",
            "Model weights saved in /tmp/tmp307g0vvd/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp307g0vvd/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp307g0vvd/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a79a7e39f46e4591a73b03fcaae5f79f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/313M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at a7658ef9563642b01d0ea45745020ffd36e21977 but expected 02f5c1d5c3dacefba19359c253e758bd707081bc        \n",
            "To https://huggingface.co/Sakonii/nepaliBert-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBert-clf'\n",
            "\n",
            "Error pushing update to the model card. Please read logs and retry.\n",
            "$remote: error: cannot lock ref 'refs/heads/main': is at a7658ef9563642b01d0ea45745020ffd36e21977 but expected 02f5c1d5c3dacefba19359c253e758bd707081bc        \n",
            "To https://huggingface.co/Sakonii/nepaliBert-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBert-clf'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2485, training_loss=0.48791578015091436, metrics={'train_runtime': 735.0743, 'train_samples_per_second': 87.869, 'train_steps_per_second': 3.381, 'total_flos': 8558205474078720.0, 'train_loss': 0.48791578015091436, 'epoch': 5.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lr=3e-5, bs=26, vram_load_titanv=99.08%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6db0320746484e51a35ce36b61e632dd"
          ]
        },
        "id": "yO4MykFZLiOL",
        "outputId": "8f1a320e-43ed-411d-e6e2-f481ad5196a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 26\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 26\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2485\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220327_144535-18ep99xm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/18ep99xm\" target=\"_blank\">NepaliBERT-clf-bs_26-lr_2e-5-linear_lr_scheduler</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2486' max='2485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2485/2485 11:22, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.680200</td>\n",
              "      <td>0.809565</td>\n",
              "      <td>0.751037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.531700</td>\n",
              "      <td>0.791739</td>\n",
              "      <td>0.777317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.397400</td>\n",
              "      <td>0.721084</td>\n",
              "      <td>0.800830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.331000</td>\n",
              "      <td>0.700526</td>\n",
              "      <td>0.801521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.323200</td>\n",
              "      <td>0.724510</td>\n",
              "      <td>0.804288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-497\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-497/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-497/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-497/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-497/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-994\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-994/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-994/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-994/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-994/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1491\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1491/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1491/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1491/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1491/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1988\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1988/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1988/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1988/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1988/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 26\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2485\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2485/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2485/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2485/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2485/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/nepaliBert-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp4xgkvltb\n",
            "Configuration saved in /tmp/tmp4xgkvltb/config.json\n",
            "Model weights saved in /tmp/tmp4xgkvltb/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp4xgkvltb/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp4xgkvltb/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6db0320746484e51a35ce36b61e632dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/313M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at e5d05ae3b634c8d7b38adb7a74d6828e596df469 but expected 511b188ff89812b98de8213a79e6dbc0c79f775f        \n",
            "To https://huggingface.co/Sakonii/nepaliBert-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBert-clf'\n",
            "\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at e5d05ae3b634c8d7b38adb7a74d6828e596df469 but expected 511b188ff89812b98de8213a79e6dbc0c79f775f        \nTo https://huggingface.co/Sakonii/nepaliBert-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBert-clf'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1018\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# lr=2e-5, bs=26\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1559\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstop_and_update_metrics(metrics)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(metrics)\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainOutput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, train_loss, metrics)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:350\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:388\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/integrations.py:630\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m fake_trainer \u001b[38;5;241m=\u001b[39m Trainer(args\u001b[38;5;241m=\u001b[39margs, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[0;32m--> 630\u001b[0m     \u001b[43mfake_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m         {\n\u001b[1;32m    633\u001b[0m             k: v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m         }\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2105\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n\u001b[0;32m-> 2105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2845\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_world_process_zero():\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2845\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   2847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1251\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1023\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
            "\u001b[0;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at e5d05ae3b634c8d7b38adb7a74d6828e596df469 but expected 511b188ff89812b98de8213a79e6dbc0c79f775f        \nTo https://huggingface.co/Sakonii/nepaliBert-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/nepaliBert-clf'\n"
          ]
        }
      ],
      "source": [
        "# lr=2e-5, bs=26, vram_load_titanv=99.08%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1QcAovSLiOL",
        "outputId": "83cec53a-db28-4152-998a-3ee8f30a66c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2695\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1292' max='2695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1292/2695 05:28 < 05:57, 3.93 it/s, Epoch 2.40/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>1.220649</td>\n",
              "      <td>0.719917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.124600</td>\n",
              "      <td>1.141809</td>\n",
              "      <td>0.776625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-539\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-539/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-539/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-539/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-539/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1078\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1078/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1078/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1078/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1078/special_tokens_map.json\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1400\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1400\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1403\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1406\u001b[0m ):\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1994\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1991\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_grad_scaling:\n\u001b[0;32m-> 1994\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_apex:\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mscale_loss(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer) \u001b[38;5;28;01mas\u001b[39;00m scaled_loss:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# lr=5e-5, bs=24\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtEo8awgLiOL"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLVCOm9fLiOL",
        "tags": []
      },
      "source": [
        "### distilbert-base-nepali [Ours]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f5490230bda14aa99700ab142290edf3"
          ]
        },
        "id": "r0OMnlYuLiOL",
        "outputId": "a4f5474a-4b96-4845-a1ef-ce8c849f5ebb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2020\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220328_031327-1onivrue</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/1onivrue\" target=\"_blank\">distilbert-base-ours-clf-bs_32-lr_1e-5</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2021' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2020/2020 10:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.698600</td>\n",
              "      <td>0.664462</td>\n",
              "      <td>0.827801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.620700</td>\n",
              "      <td>0.558308</td>\n",
              "      <td>0.837483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.419900</td>\n",
              "      <td>0.511091</td>\n",
              "      <td>0.854772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.348800</td>\n",
              "      <td>0.481149</td>\n",
              "      <td>0.860304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.387700</td>\n",
              "      <td>0.489439</td>\n",
              "      <td>0.856155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/checkpoint-404\n",
            "Configuration saved in clf-16NepaliNews-train_/checkpoint-404/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/checkpoint-404/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/checkpoint-404/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/checkpoint-404/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/checkpoint-808\n",
            "Configuration saved in clf-16NepaliNews-train_/checkpoint-808/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/checkpoint-808/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/checkpoint-808/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/checkpoint-808/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/checkpoint-1212\n",
            "Configuration saved in clf-16NepaliNews-train_/checkpoint-1212/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/checkpoint-1212/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/checkpoint-1212/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/checkpoint-1212/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/checkpoint-1616\n",
            "Configuration saved in clf-16NepaliNews-train_/checkpoint-1616/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/checkpoint-1616/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/checkpoint-1616/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/checkpoint-1616/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/checkpoint-2020\n",
            "Configuration saved in clf-16NepaliNews-train_/checkpoint-2020/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/checkpoint-2020/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/checkpoint-2020/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/checkpoint-2020/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train_/ is already a clone of https://huggingface.co/Sakonii/distilbert-base-nepali-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp8e2_8ehb\n",
            "Configuration saved in /tmp/tmp8e2_8ehb/config.json\n",
            "Model weights saved in /tmp/tmp8e2_8ehb/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp8e2_8ehb/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp8e2_8ehb/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train_/\n",
            "Configuration saved in clf-16NepaliNews-train_/config.json\n",
            "Model weights saved in clf-16NepaliNews-train_/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train_/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train_/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5490230bda14aa99700ab142290edf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at c2e48a44b215d44616ace7c2e88f35a30578c236 but expected d7f93e8c7c3b06ccb61b894d776c76f9c785a73e        \n",
            "To https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
            "\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at c2e48a44b215d44616ace7c2e88f35a30578c236 but expected d7f93e8c7c3b06ccb61b894d776c76f9c785a73e        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1018\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# lr=1e-5, bs=32, vram_load_titanv=99.59%\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1559\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstop_and_update_metrics(metrics)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(metrics)\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainOutput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, train_loss, metrics)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:350\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:388\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/integrations.py:630\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m fake_trainer \u001b[38;5;241m=\u001b[39m Trainer(args\u001b[38;5;241m=\u001b[39margs, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[0;32m--> 630\u001b[0m     \u001b[43mfake_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m         {\n\u001b[1;32m    633\u001b[0m             k: v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m         }\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2105\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n\u001b[0;32m-> 2105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2845\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_world_process_zero():\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2845\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   2847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1251\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1023\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
            "\u001b[0;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at c2e48a44b215d44616ace7c2e88f35a30578c236 but expected d7f93e8c7c3b06ccb61b894d776c76f9c785a73e        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n"
          ]
        }
      ],
      "source": [
        "# lr=1e-5, bs=32, vram_load_titanv=99.59%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "23b98f909b6b43c194b38c9894e17945"
          ]
        },
        "id": "eLj3WT4aLiOM",
        "outputId": "e5f43543-be28-404d-ee52-ddb2d021d612"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1616\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220326_122631-2lk7zsuz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/2lk7zsuz\" target=\"_blank\">distilbert-base-nepali-clf-bs_32-lr_2e-5-linear_lr_scheduler</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1616' max='1616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1616/1616 15:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.597500</td>\n",
              "      <td>0.545496</td>\n",
              "      <td>0.843015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.424700</td>\n",
              "      <td>0.456841</td>\n",
              "      <td>0.872752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.431343</td>\n",
              "      <td>0.883126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.250100</td>\n",
              "      <td>0.432083</td>\n",
              "      <td>0.879668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-404\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-404/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-404/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-404/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-404/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-808\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-808/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-808/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-808/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-808/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1212\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1212/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1212/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1212/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1212/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1616\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1616/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1616/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1616/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1616/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/distilbert-base-nepali-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmp8__g4q0l\n",
            "Configuration saved in /tmp/tmp8__g4q0l/config.json\n",
            "Model weights saved in /tmp/tmp8__g4q0l/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp8__g4q0l/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp8__g4q0l/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23b98f909b6b43c194b38c9894e17945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at 39371db1bd3ce2d3331045a93babc33c8614ed91 but expected bc990c29900c85016238c6a7c3bcf69625cb8f12        \n",
            "To https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
            "\n",
            "Error pushing update to the model card. Please read logs and retry.\n",
            "$remote: error: cannot lock ref 'refs/heads/main': is at 39371db1bd3ce2d3331045a93babc33c8614ed91 but expected bc990c29900c85016238c6a7c3bcf69625cb8f12        \n",
            "To https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1616, training_loss=0.5129271843240107, metrics={'train_runtime': 526.1828, 'train_samples_per_second': 98.202, 'train_steps_per_second': 3.071, 'total_flos': 6846514691586048.0, 'train_loss': 0.5129271843240107, 'epoch': 4.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lr=2e-5, bs=32, vram_load_titanv=99.59%\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "acbae7025e5442b4bc209d5ddd318419"
          ]
        },
        "id": "fzb2jRoNLiOM",
        "outputId": "34be75b2-0cf9-43cf-9ee2-ed43356623e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4040\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220326_115053-1soinb4z</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/1soinb4z\" target=\"_blank\">xlm-roberta-base-clf-bs_32-lr_3e-5-linear_lr_scheduler</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4041' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4040/4040 21:22, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.547400</td>\n",
              "      <td>0.467114</td>\n",
              "      <td>0.867220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.357700</td>\n",
              "      <td>0.456065</td>\n",
              "      <td>0.863071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.281900</td>\n",
              "      <td>0.413905</td>\n",
              "      <td>0.876902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.528043</td>\n",
              "      <td>0.856846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.102300</td>\n",
              "      <td>0.560290</td>\n",
              "      <td>0.860996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.037200</td>\n",
              "      <td>0.630840</td>\n",
              "      <td>0.852006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>0.638768</td>\n",
              "      <td>0.863762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.694790</td>\n",
              "      <td>0.865145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.707877</td>\n",
              "      <td>0.864454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.716457</td>\n",
              "      <td>0.866528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-404\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-404/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-404/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-404/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-404/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-808\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-808/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-808/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-808/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-808/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1212\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1212/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1212/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1212/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1212/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1616\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1616/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1616/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1616/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1616/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2020\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2020/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2020/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2020/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2020/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2424\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2424/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2424/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2424/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2424/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-2828\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-2828/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-2828/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-2828/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-2828/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-3232\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-3232/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-3232/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-3232/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-3232/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-3636\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-3636/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-3636/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-3636/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-3636/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-4040\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-4040/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-4040/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-4040/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-4040/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/distilbert-base-nepali-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmps8_gm4mk\n",
            "Configuration saved in /tmp/tmps8_gm4mk/config.json\n",
            "Model weights saved in /tmp/tmps8_gm4mk/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmps8_gm4mk/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmps8_gm4mk/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acbae7025e5442b4bc209d5ddd318419",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at a87e8c68f62f674cb8c990bf6408d4d1b9ad52ea but expected 7789a790c8a6bbbdcc649b30c520f991947ecc3c        \n",
            "To https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
            "\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at a87e8c68f62f674cb8c990bf6408d4d1b9ad52ea but expected 7789a790c8a6bbbdcc649b30c520f991947ecc3c        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1018\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1559\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstop_and_update_metrics(metrics)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(metrics)\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainOutput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, train_loss, metrics)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:350\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:388\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/integrations.py:630\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m fake_trainer \u001b[38;5;241m=\u001b[39m Trainer(args\u001b[38;5;241m=\u001b[39margs, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[0;32m--> 630\u001b[0m     \u001b[43mfake_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m         {\n\u001b[1;32m    633\u001b[0m             k: v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m         }\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2105\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n\u001b[0;32m-> 2105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2845\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_world_process_zero():\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2845\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   2847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1251\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1023\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
            "\u001b[0;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at a87e8c68f62f674cb8c990bf6408d4d1b9ad52ea but expected 7789a790c8a6bbbdcc649b30c520f991947ecc3c        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n"
          ]
        }
      ],
      "source": [
        "# lr=3e-5\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geW4pqd5LiOM",
        "outputId": "2863b5b5-042b-43da-d2e1-7fac44c1a8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VlQ7lUWLiOM",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### xlm-roberta-base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "40843dfb9c754dc9b190fb12df3fe94e"
          ]
        },
        "id": "aZ0mwc-kIbKW",
        "outputId": "98d39f97-b968-4123-a1ae-3bfb85beca8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 12918\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16150\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/storage0/utsavm/wandb/run-20220325_225640-3l24jt9s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/3l24jt9s\" target=\"_blank\">xlm-roberta-base-clf-bs_7-lr_5e-5-linear_lr_scheduler</a></strong> to <a href=\"https://wandb.ai/sakonii/NLMUT_CLF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16151' max='16150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16150/16150 1:16:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.480900</td>\n",
              "      <td>0.830831</td>\n",
              "      <td>0.782849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.205900</td>\n",
              "      <td>0.829219</td>\n",
              "      <td>0.760719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.819400</td>\n",
              "      <td>0.619980</td>\n",
              "      <td>0.825726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.686500</td>\n",
              "      <td>0.775610</td>\n",
              "      <td>0.807746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.407300</td>\n",
              "      <td>0.659548</td>\n",
              "      <td>0.840249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.693200</td>\n",
              "      <td>0.832789</td>\n",
              "      <td>0.817427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.397200</td>\n",
              "      <td>0.854190</td>\n",
              "      <td>0.836791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.187100</td>\n",
              "      <td>0.921899</td>\n",
              "      <td>0.839557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.285900</td>\n",
              "      <td>1.061323</td>\n",
              "      <td>0.811895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.428700</td>\n",
              "      <td>1.045193</td>\n",
              "      <td>0.817427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-1615\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-1615/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-1615/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-1615/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-1615/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (3) will be pushed upstream.\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-3230\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-3230/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-3230/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-3230/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-3230/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-4845\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-4845/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-4845/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-4845/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-4845/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-6460\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-6460/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-6460/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-6460/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-6460/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-8075\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-8075/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-8075/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-8075/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-8075/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-9690\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-9690/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-9690/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-9690/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-9690/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-11305\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-11305/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-11305/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-11305/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-11305/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-12920\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-12920/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-12920/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-12920/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-12920/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-14535\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-14535/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-14535/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-14535/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-14535/special_tokens_map.json\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1443: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  nn.utils.clip_grad_norm_(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1446\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to clf-16NepaliNews-train/checkpoint-16150\n",
            "Configuration saved in clf-16NepaliNews-train/checkpoint-16150/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/checkpoint-16150/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/checkpoint-16150/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/checkpoint-16150/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/mnt/storage0/utsavm/clf-16NepaliNews-train/ is already a clone of https://huggingface.co/Sakonii/distilbert-base-nepali-clf. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n",
            "Saving model checkpoint to /tmp/tmpl4eymabf\n",
            "Configuration saved in /tmp/tmpl4eymabf/config.json\n",
            "Model weights saved in /tmp/tmpl4eymabf/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmpl4eymabf/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmpl4eymabf/special_tokens_map.json\n",
            "Saving model checkpoint to clf-16NepaliNews-train/\n",
            "Configuration saved in clf-16NepaliNews-train/config.json\n",
            "Model weights saved in clf-16NepaliNews-train/pytorch_model.bin\n",
            "tokenizer config file saved in clf-16NepaliNews-train/tokenizer_config.json\n",
            "Special tokens file saved in clf-16NepaliNews-train/special_tokens_map.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40843dfb9c754dc9b190fb12df3fe94e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: error: cannot lock ref 'refs/heads/main': is at eed81a0a0f907c3b76d8bfc897e30b762f4c09e4 but expected e930b42cc688ddb2507449c0b31f963f3e840e44        \n",
            "To https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n",
            " ! [remote rejected] main -> main (failed to update ref)\n",
            "error: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
            "\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at eed81a0a0f907c3b76d8bfc897e30b762f4c09e4 but expected e930b42cc688ddb2507449c0b31f963f3e840e44        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1018\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:1559\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker\u001b[38;5;241m.\u001b[39mstop_and_update_metrics(metrics)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(metrics)\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainOutput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, train_loss, metrics)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:350\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer_callback.py:388\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/integrations.py:630\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m fake_trainer \u001b[38;5;241m=\u001b[39m Trainer(args\u001b[38;5;241m=\u001b[39margs, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[0;32m--> 630\u001b[0m     \u001b[43mfake_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m         {\n\u001b[1;32m    633\u001b[0m             k: v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m         }\n\u001b[1;32m    642\u001b[0m     )\n\u001b[1;32m    643\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2105\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n\u001b[0;32m-> 2105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/transformers/trainer.py:2845\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_world_process_zero():\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2845\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   2847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1251\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/storage0/utsavm/miniconda3/envs/NLMUT/lib/python3.9/site-packages/huggingface_hub/repository.py:1023\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m   1019\u001b[0m                     return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr\n\u001b[1;32m   1020\u001b[0m                 )\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
            "\u001b[0;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at eed81a0a0f907c3b76d8bfc897e30b762f4c09e4 but expected e930b42cc688ddb2507449c0b31f963f3e840e44        \nTo https://huggingface.co/Sakonii/distilbert-base-nepali-clf\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Sakonii/distilbert-base-nepali-clf'\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "RzwnsNJ3LiOM",
        "outputId": "d19d464e-e3d5-4db5-d274-9254480dd16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▃▁▇▅█▆██▆▆</td></tr><tr><td>eval/loss</td><td>▄▄▁▃▂▄▅▆██</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▃▁▁█▁</td></tr><tr><td>eval/samples_per_second</td><td>█▇███▅██▁█</td></tr><tr><td>eval/steps_per_second</td><td>█▇███▅██▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▃▃▄▃▄▅▄▂▄▂▂▃▃▂▂▄▂▃▃▄▂▂▃▄▃▂▂▂▃▁▃▂▁▁▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81743</td></tr><tr><td>eval/loss</td><td>1.04519</td></tr><tr><td>eval/runtime</td><td>9.8359</td></tr><tr><td>eval/samples_per_second</td><td>147.012</td></tr><tr><td>eval/steps_per_second</td><td>18.402</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>16150</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4287</td></tr><tr><td>train/total_flos</td><td>3.3685842597631104e+16</td></tr><tr><td>train/train_loss</td><td>0.52018</td></tr><tr><td>train/train_runtime</td><td>4700.5184</td></tr><tr><td>train/train_samples_per_second</td><td>27.482</td></tr><tr><td>train/train_steps_per_second</td><td>3.436</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">xlm-roberta-base-clf-bs_7-lr_5e-5-linear_lr_scheduler</strong>: <a href=\"https://wandb.ai/sakonii/NLMUT_CLF/runs/3l24jt9s\" target=\"_blank\">https://wandb.ai/sakonii/NLMUT_CLF/runs/3l24jt9s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220325_225640-3l24jt9s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pnxxmwoLiOM"
      },
      "source": [
        "## Push to hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3bz6FMIrd2l"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSmcQ9ajLiON"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O-1SFcQGd9ru",
        "5Dek0SRUtZS2",
        "Y_ypFRwUtU3I",
        "91Tsgz94WEhr",
        "EgQ2I0PNIQOS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01aeb73ae6e1475180f88cd4d0b68cab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0694e0ba0418483abd29b15c33d96221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a98a21e322342c09855d5a3a035a9b6",
            "max": 1446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_776da3688d5b4ffdadb570ff89241efc",
            "value": 1446
          }
        },
        "0d4ee81856c14efbb6ba9ce9f2091154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100def69a7d2472497d5fb0ada7c5dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01aeb73ae6e1475180f88cd4d0b68cab",
            "placeholder": "​",
            "style": "IPY_MODEL_5b04baf66f614a93afb9bc55ac0e5987",
            "value": " 964k/964k [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "10c910efbe01465aae96d39aac5e5a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42b9bc46d9b400b8412eee53bcc47ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f569aaa0528c4ef381743ef075c5d1f3",
            "value": "100%"
          }
        },
        "10fbb924da50491793a9d8c7ec8e37f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b4a2b16e9f4714aceefc0435194287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1711b157d65a461e80c50565f8ecd18d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f98f725b8e49e6bbea948ae4265d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c5103e1f150406c9c10ce47577120c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c01bf44c7145b1a91852d996d6afc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2200c2cd71e64aa5ba1f1c4d7b9da527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10c910efbe01465aae96d39aac5e5a5e",
              "IPY_MODEL_dcb89119c66a44ca8451e4017a5646ea",
              "IPY_MODEL_3a0b9dcd7d7f41a59a7ff385a8fe8c88"
            ],
            "layout": "IPY_MODEL_20c01bf44c7145b1a91852d996d6afc7"
          }
        },
        "224875caf7364181a32f71096ad6b1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10fbb924da50491793a9d8c7ec8e37f7",
            "placeholder": "​",
            "style": "IPY_MODEL_d4f42d94d70e4d2d91ffa788784754f2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "23c609c4fdf649768a2f88981edcdff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f10c106e1948b8ba7ca108b576abe1",
            "placeholder": "​",
            "style": "IPY_MODEL_3a5f54064b4e4e4e9b831445cdeba971",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "25269636d5384dbc8727dcee39e719b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2667d5c2e09e4d3b85eb253e7029105e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed387bf621994c7c81c46778b83c942d",
              "IPY_MODEL_adefb92dbb33405ba4c97520fac3aa71",
              "IPY_MODEL_2b25268aa2b1466bb6a294ea921c786f"
            ],
            "layout": "IPY_MODEL_b0c19f4eec3b4cf597342bd0a4658d05"
          }
        },
        "27a4bdd2ffee4fa1b728140d3f63d026": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c88008697e448b92130ba83a19fa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2a9a727cf2d74a09b6a3b4a9a6d3ea24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b25268aa2b1466bb6a294ea921c786f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f445dd46d1a4014a24985901ff22d77",
            "placeholder": "​",
            "style": "IPY_MODEL_72cae5449de04a10930b0acc92e83ab8",
            "value": " 13/13 [02:10&lt;00:00,  8.51s/ba]"
          }
        },
        "2eff3a77dde841bf83cf6f14ecb87948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f445dd46d1a4014a24985901ff22d77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f9d8b8b1e77415ebdd119f97830a8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30258314778e4e049d96e37892cda4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34c90f8222eb4063b4e460fdfdbd28da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37edd3df6aa549c7a419364f20063669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f10c106e1948b8ba7ca108b576abe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0b9dcd7d7f41a59a7ff385a8fe8c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9a727cf2d74a09b6a3b4a9a6d3ea24",
            "placeholder": "​",
            "style": "IPY_MODEL_7118547fc5844f7ca2e9143b4cbed80b",
            "value": " 2/2 [00:00&lt;00:00, 26.93it/s]"
          }
        },
        "3a5f54064b4e4e4e9b831445cdeba971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bba2059fcde4ecfb621ab94716ecf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb3a8f6f1aa4a92a637bb7f057ae049",
            "placeholder": "​",
            "style": "IPY_MODEL_2f9d8b8b1e77415ebdd119f97830a8ca",
            "value": "Downloading: 100%"
          }
        },
        "3d4c85919ad948f889be6ca4288d1115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "420e255eeb904e36a423e87e2b3d91df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_27a4bdd2ffee4fa1b728140d3f63d026",
            "style": "IPY_MODEL_6023d1806f9f4c15b905f9b8e464324e",
            "tooltip": ""
          }
        },
        "477422a0d59a41ef9730e31aa53e79d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c871686b1fb44498a626ffb8245e5e40",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a651b9f3954090856304a36fe95a74",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "4e5519315df045eb8ae5c9459754629d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522ec6cf07c34acb9a51e61cb11260f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547bc82d71d3418785f17bc4c51c1afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b7433473e14184bf382e7e589dcf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c942f7bf535946d688bf26c50a107962",
              "IPY_MODEL_c4087d3aaf8643dc8a76f4a6ed8b3b25",
              "IPY_MODEL_d0ce1afc1df141be9a1e94c7f840b33f"
            ],
            "layout": "IPY_MODEL_34c90f8222eb4063b4e460fdfdbd28da"
          }
        },
        "5a98a21e322342c09855d5a3a035a9b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b04baf66f614a93afb9bc55ac0e5987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6023d1806f9f4c15b905f9b8e464324e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "60f61fd8c3f840f8ae4ac42c3db83fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63cdee9b24fc43159493a3ec21aeb0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6619d7fc4e694e07b2358e4c30ab5a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bba2059fcde4ecfb621ab94716ecf84",
              "IPY_MODEL_aae5c112fd1a4fabbf3ca00ff246b454",
              "IPY_MODEL_100def69a7d2472497d5fb0ada7c5dff"
            ],
            "layout": "IPY_MODEL_f61ec379fa4f4bcb986ad2b3986d3469"
          }
        },
        "69938506e9c743f08efbf9e0c293c28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f844501897f4c58a5826bcdf2bfcfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7118547fc5844f7ca2e9143b4cbed80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72cae5449de04a10930b0acc92e83ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7301bd2dac6d4fa7b50335f006729b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74e3820b56b74cd79683a957a934d9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755b497bb1e7480d8ac80b68702f4c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522ec6cf07c34acb9a51e61cb11260f9",
            "placeholder": "​",
            "style": "IPY_MODEL_e2830c743f884d118de538c76642a351",
            "value": "100%"
          }
        },
        "776da3688d5b4ffdadb570ff89241efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78213c9028774f409ab0c8d615077870": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f608d33e6c47fbb3e1038c7a013c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819c329b3fbd48c89fde436ddf131ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8548e03776344dde852ef9ed23efb4df",
            "placeholder": "​",
            "style": "IPY_MODEL_69938506e9c743f08efbf9e0c293c28f",
            "value": ""
          }
        },
        "84848296a05e41238d9e7fa76ca357f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8548e03776344dde852ef9ed23efb4df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c667e6eb38437a9bd4178e20bbe1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_74e3820b56b74cd79683a957a934d9a8",
            "style": "IPY_MODEL_25269636d5384dbc8727dcee39e719b0",
            "tooltip": ""
          }
        },
        "8f5deda705574d9f94f603e597ab9dee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa96e310e2442fb930513ff012fdabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9c39e87bc68d4d12900ca258b582263a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a224f24787884bfa947e8f93291c3437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fcb137e4046b4a338186bbf659fb4c2a",
            "style": "IPY_MODEL_9aa96e310e2442fb930513ff012fdabd",
            "tooltip": ""
          }
        },
        "a87203c1372a4c94a51773c67cd74749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae5c112fd1a4fabbf3ca00ff246b454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5519315df045eb8ae5c9459754629d",
            "max": 987396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da18174543b44352840cdfede7e71985",
            "value": 987396
          }
        },
        "adefb92dbb33405ba4c97520fac3aa71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d283bd3eb55e43d38c873f4892105082",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c39e87bc68d4d12900ca258b582263a",
            "value": 13
          }
        },
        "b0c19f4eec3b4cf597342bd0a4658d05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b136a9d38f08450cba9a046dbe17f2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bd0d4f1d2543c3a8b4d2c60d57f542": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f844501897f4c58a5826bcdf2bfcfaf",
            "placeholder": "​",
            "style": "IPY_MODEL_30258314778e4e049d96e37892cda4a3",
            "value": " 2/2 [00:12&lt;00:00,  5.77s/ba]"
          }
        },
        "bbcf01e8d9264812a740d06dcbbb5fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_224875caf7364181a32f71096ad6b1f2",
              "IPY_MODEL_819c329b3fbd48c89fde436ddf131ca4",
              "IPY_MODEL_420e255eeb904e36a423e87e2b3d91df",
              "IPY_MODEL_cf8f249f35c04374986e09aa7621c7d8",
              "IPY_MODEL_86c667e6eb38437a9bd4178e20bbe1be"
            ],
            "layout": "IPY_MODEL_3d4c85919ad948f889be6ca4288d1115"
          }
        },
        "bfb40e7f2b234b5798eae0c06239cc35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d59ae181a04613b0402f7bdac68700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3bd3ee8380c42b78bae8488e42e5df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cba992151adb4291a7d7502b9f74f58a",
              "IPY_MODEL_0694e0ba0418483abd29b15c33d96221",
              "IPY_MODEL_f4993acbc56b42f5a19e7dd402c08366"
            ],
            "layout": "IPY_MODEL_b136a9d38f08450cba9a046dbe17f2cd"
          }
        },
        "c4087d3aaf8643dc8a76f4a6ed8b3b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61fc3c0c48e4a939b97dfe5c7076af8",
            "max": 12918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12b4a2b16e9f4714aceefc0435194287",
            "value": 12918
          }
        },
        "c42b9bc46d9b400b8412eee53bcc47ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c844d078f9bd42caae0b4438719eeff9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c871686b1fb44498a626ffb8245e5e40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c942f7bf535946d688bf26c50a107962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95babf12826482c9ff5065ab844b0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_19f98f725b8e49e6bbea948ae4265d6c",
            "value": "100%"
          }
        },
        "cba992151adb4291a7d7502b9f74f58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c5103e1f150406c9c10ce47577120c0",
            "placeholder": "​",
            "style": "IPY_MODEL_2eff3a77dde841bf83cf6f14ecb87948",
            "value": "100%"
          }
        },
        "cf8f249f35c04374986e09aa7621c7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78213c9028774f409ab0c8d615077870",
            "placeholder": "​",
            "style": "IPY_MODEL_63cdee9b24fc43159493a3ec21aeb0d7",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "d0ce1afc1df141be9a1e94c7f840b33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1711b157d65a461e80c50565f8ecd18d",
            "placeholder": "​",
            "style": "IPY_MODEL_c0d59ae181a04613b0402f7bdac68700",
            "value": " 12918/12918 [00:14&lt;00:00, 994.32ex/s]"
          }
        },
        "d283bd3eb55e43d38c873f4892105082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36e39a733304b48ba5e44cf9100d2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7bf5db35d3c4afa9e56571f3d75118b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d4ee81856c14efbb6ba9ce9f2091154",
            "value": 2
          }
        },
        "d3b234dc14e240378da0ef414099cd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_477422a0d59a41ef9730e31aa53e79d1",
              "IPY_MODEL_d3c20717e97c448ca3c28fb6641217c6",
              "IPY_MODEL_fba2f8821114446fa9b7afe7d4764af2",
              "IPY_MODEL_23c609c4fdf649768a2f88981edcdff1",
              "IPY_MODEL_a224f24787884bfa947e8f93291c3437"
            ],
            "layout": "IPY_MODEL_c844d078f9bd42caae0b4438719eeff9"
          }
        },
        "d3c20717e97c448ca3c28fb6641217c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8f5deda705574d9f94f603e597ab9dee",
            "placeholder": "​",
            "style": "IPY_MODEL_7301bd2dac6d4fa7b50335f006729b15",
            "value": ""
          }
        },
        "d4f42d94d70e4d2d91ffa788784754f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8a5899196694978b9945444cae8df10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_755b497bb1e7480d8ac80b68702f4c85",
              "IPY_MODEL_d36e39a733304b48ba5e44cf9100d2f6",
              "IPY_MODEL_b2bd0d4f1d2543c3a8b4d2c60d57f542"
            ],
            "layout": "IPY_MODEL_60f61fd8c3f840f8ae4ac42c3db83fa1"
          }
        },
        "da18174543b44352840cdfede7e71985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcb89119c66a44ca8451e4017a5646ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f608d33e6c47fbb3e1038c7a013c7a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_547bc82d71d3418785f17bc4c51c1afb",
            "value": 2
          }
        },
        "e2830c743f884d118de538c76642a351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e766665540524efb8f46672981937f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bf5db35d3c4afa9e56571f3d75118b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95babf12826482c9ff5065ab844b0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed387bf621994c7c81c46778b83c942d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84848296a05e41238d9e7fa76ca357f1",
            "placeholder": "​",
            "style": "IPY_MODEL_37edd3df6aa549c7a419364f20063669",
            "value": "100%"
          }
        },
        "efb3a8f6f1aa4a92a637bb7f057ae049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4993acbc56b42f5a19e7dd402c08366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e766665540524efb8f46672981937f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_a87203c1372a4c94a51773c67cd74749",
            "value": " 1446/1446 [00:01&lt;00:00, 929.61ex/s]"
          }
        },
        "f569aaa0528c4ef381743ef075c5d1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a651b9f3954090856304a36fe95a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f61ec379fa4f4bcb986ad2b3986d3469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61fc3c0c48e4a939b97dfe5c7076af8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba2f8821114446fa9b7afe7d4764af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bfb40e7f2b234b5798eae0c06239cc35",
            "style": "IPY_MODEL_28c88008697e448b92130ba83a19fa37",
            "tooltip": ""
          }
        },
        "fcb137e4046b4a338186bbf659fb4c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
